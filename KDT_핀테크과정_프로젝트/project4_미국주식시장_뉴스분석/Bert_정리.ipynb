{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85259aa",
   "metadata": {},
   "source": [
    "# Bert 연습해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea18c33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T06:40:38.016600Z",
     "start_time": "2022-04-16T06:40:37.998620Z"
    }
   },
   "source": [
    "## 임베딩을 사용하는 방법\n",
    "1. 임베딩층(Embedding layer)을 랜덤 초기화하여 처음부터 학습하는 방법\n",
    "2. 방대한 데이터로 Word2Vec등과 같은 임베딩 알고리즘으로 사전에 학습된 임베딩 벡터를 가져와 사용하는 방법\n",
    "\n",
    "## 임베딩의 한계 및 해결책\n",
    "* 하나의 단어가 하나의 벡터값으로 맵핑되어 문맥을 고려하지 못하는 한계가 있음<br>\n",
    " -> 사전 훈련된 언어모델인 ELMo나 BERT 등으로 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0112ca",
   "metadata": {},
   "source": [
    "## Bert 전 모델들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058a6d0",
   "metadata": {},
   "source": [
    "### Semi-superviesed Sequence Learning<br>\n",
    ":LSTM 언어 모델을 학습하고나서 이렇게 학습한 LSTM을 텍스트 분류에 추가 학습하는 방법\n",
    "\n",
    "* 언어 모델은 주어진 텍스트로부터 이전 단어들로부터 다음 단어를 예측하도록 학습하므로 기본적으로 별도의 레이블이 부착되지 않은 텍스트 데이터로도 학습 가능(사전 훈련된 언어 모델의 강점은 학습 전 사람이 별도 레이블을 지정해줄 필요가 없다는 점)\n",
    "* 레이블이 없는 데이터로 학습된 LSTM과 가중치가 랜덤으로 초기화 된 LSTM 두 가지를 두고, 텍스트 분류와 같은 문제를 학습하여 사전 훈련된 언어 모델을 사용한 전자의 경우가 더 좋은 성능을 얻을 수 있다는 가능성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb4ff3",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/108730/image1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e89cd",
   "metadata": {},
   "source": [
    "### ELMo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e09df1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T07:26:57.315849Z",
     "start_time": "2022-04-16T07:26:57.308840Z"
    }
   },
   "source": [
    "* ELMo는 순방향 언어 모델과 역방향 언어 모델을 각각 따로 학습시킨 후에, \n",
    "이렇게 사전 학습된 언어 모델로부터 임베딩 값을 얻는다는 아이디어\n",
    "\n",
    "* 이러한 임베딩은 문맥에 따라서 임베딩 벡터값이 달라지므로, 기존 워드 임베딩인 Word2Vec이나 GloVe 등이 \n",
    "다의어를 구분할 수 없었던 문제점을 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cbcfc",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/108730/image2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd78809",
   "metadata": {},
   "source": [
    "### GPT\n",
    "-> LSTM 대신 Transformer사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b1741",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/108730/image3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d0da9",
   "metadata": {},
   "source": [
    "### 양방향 모델\n",
    "양방향 언어 모델은 지금까지 본 적 없던 형태의 언어 모델입니다. <br>\n",
    "실제로 이렇게 구현하는 경우는 거의 없는데 그 이유가 무엇일까요?<br> \n",
    "가령, 양방향 LSTM을 이용해서 우측과 같은 언어 모델을 만들었다고 해봅시다. <br>\n",
    "초록색 LSTM 셀은 순방향 언어 모델로 <sos>를 입력받아 I를 예측하고, 그 후에 am을 예측합니다. <br>\n",
    "그런데 am을 예측할 때, 출력층은 주황색 LSTM 셀인 역방향 언어 모델의 정보도 함께 받고있습니다. <br>\n",
    "그런데 am을 예측하는 시점에서 역방향 언어 모델이 이미 관측한 단어는 a, am, I 이렇게 3개의 단어입니다. <br>\n",
    "이미 예측해야하는 단어를 역방향 언어 모델을 통해 미리 관측한 셈이므로 언어 모델은 일반적으로 양방향으로 구현하지 않습니다.<br>\n",
    "<br>\n",
    "이와 같이 기존 언어 모델로는 양방향 구조를 도입할 수 없으므로, <br>\n",
    "양방향 구조를 도입하기 위해서 2018년에는 새로운 구조의 언어 모델이 탄생했는데 <br>\n",
    "바로 마스크드 언어 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758b848",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/108730/image4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3297e",
   "metadata": {},
   "source": [
    "## BERT(Bidirectional Encoder Representations from Transformers) 란?\n",
    " :BERT는 이전 챕터에서 배웠던 트랜스포머를 이용하여 구현되었으며,<br>\n",
    " 위키피디아(25억 단어)와 BooksCorpus(8억 단어)와 같은 레이블이 없는 텍스트 데이터로 사전 훈련된 언어 모델\n",
    " \n",
    "### 마스크드 언어 모델(Masked Language Model)\n",
    ": BERT는 사전 훈련을 위해서 인공신경망의 입력으로 들어가는 입력 텍스트의 15%의 단어를 랜덤으로 마스킹합니다.<br>\n",
    "그리고 인경신경망에게 이 가려진 단어들을(Masked words) 예측하도록 합니다. 중간에 단어들에 구멍을 뚫어놓고 <br>\n",
    "구멍에 들어갈 단어들을 예측하게 하는 식입니다.\n",
    "\n",
    "* 80%의 단어들은 [MASK]로 변경한다.\n",
    "Ex) The man went to the store → The man went to the [MASK]\n",
    "\n",
    "* 10%의 단어들은 랜덤으로 단어가 변경된다.\n",
    "Ex) The man went to the store → The man went to the dog\n",
    "\n",
    "* 10%의 단어들은 동일하게 둔다.\n",
    "Ex) The man went to the store → The man went to the store\n",
    "\n",
    "### 다음 문장 예측(Next Sentensce Prediction,NSP)\n",
    ": BERT는 두 개의 문장을 준 후에 이 문장이 이어지는 문장인지 아닌지를 맞추는 방식으로 훈련시킵니다. 이를 위해서 50:50 비율로 실제 이어지는 두 개의 문장과 랜덤으로 이어붙인 두 개의 문장을 주고 훈련시킵니다. 이를 각각 Sentence A와 Sentence B라고 하였을 때, 다음의 예는 문장의 연속성을 확인한 경우와 그렇지 않은 경우를 보여줍니다.\n",
    "\n",
    "* 이어지는 문장의 경우 <br>\n",
    "Sentence A : The man went to the store.<br>\n",
    "Sentence B : He bought a gallon of milk.<br>\n",
    "Label = IsNextSentence\n",
    "\n",
    "* 이어지는 문장이 아닌 경우 경우 <br>\n",
    "Sentence A : The man went to the store.<br>\n",
    "Sentence B : dogs are so cute.<br>\n",
    "Label = NotNextSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f3969",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/35594/%ED%8C%8C%EC%9D%B8%ED%8A%9C%EB%8B%9D.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3c803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T07:55:00.721664Z",
     "start_time": "2022-04-16T07:55:00.715680Z"
    }
   },
   "source": [
    "### Bert의 기본구조\n",
    ": 트랜스포머의 인코더를 쌓아올린 구조입니다. Base 버전에서는 총 12개를 쌓았으며, Large 버전에서는 총 24개를 쌓음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e105ff",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/35594/bartbase%EC%99%80large.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9520d",
   "metadata": {},
   "source": [
    "### BERT의 문맥을 반영한 임베딩(Contextual Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c86077",
   "metadata": {},
   "source": [
    "BERT는 어떻게 모든 단어들을 참고하여 문맥을 반영한 출력 임베딩을 얻게 되는 것일까요?<br>\n",
    "바로 '셀프 어텐션'입니다.<br>\n",
    "BERT는 기본적으로 트랜스포머 인코더를 12번 쌓은 것이므로 내부적으로 각 층마다<br> \n",
    "멀티 헤드 셀프 어텐션과 포지션 와이즈 피드 포워드 신경망을 수행하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572eb162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66bfd6ff",
   "metadata": {},
   "source": [
    "### BERT의 서브워드 토크나이저: WordPiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e1681",
   "metadata": {},
   "source": [
    "준비물 : 이미 훈련 데이터로부터 만들어진 단어 집합\n",
    "\n",
    "1. 토큰이 단어 집합에 존재한다.<br>\n",
    "=> 해당 토큰을 분리하지 않는다.<br>\n",
    "<br>\n",
    "2. 토큰이 단어 집합에 존재하지 않는다.<br>\n",
    "=> 해당 토큰을 서브워드로 분리한다.<br>\n",
    "=> 해당 토큰의 첫번째 서브워드를 제외한 나머지 서브워드들은 앞에 \"##\"를 붙인 것을 토큰으로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae2ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282348d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98b9a713",
   "metadata": {},
   "source": [
    "## Bert 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b678074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T13:56:58.616667Z",
     "start_time": "2022-04-16T13:56:44.669956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f153903b6714588bd60d648d33dbce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77e4c018e494334bf33cb236d409299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3f56cc9e214851b2275fac4215378a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # Bert-base의 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9572ebba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T13:57:13.264905Z",
     "start_time": "2022-04-16T13:57:13.250825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.']\n"
     ]
    }
   ],
   "source": [
    "result = tokenizer.tokenize('Here is the sentence I want embeddings for.')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04e3c8d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T13:57:30.978692Z",
     "start_time": "2022-04-16T13:57:30.969701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab['here'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258d938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fd802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614876db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97e37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d007b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a07b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbed50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16293e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca04daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56379c91",
   "metadata": {},
   "source": [
    "## KeyBERT : BERT를 사용한 키워드 추출 <br>\n",
    "BERT임베딩을 사용하고 cosine_similarity를 사용하여 키워드를 추출하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5861db7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T14:13:25.554861Z",
     "start_time": "2022-04-16T14:13:25.545885Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a357d713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:31:38.324169Z",
     "start_time": "2022-04-25T12:31:32.806613Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ac0ef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:31:38.369739Z",
     "start_time": "2022-04-25T12:31:38.356061Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "         (Reuters) - Activision Blizzard (NASDAQ:ATVI) is cooperating with federal investigations into trading by friends of its chief executive shortly before the gaming company disclosed its sale to Microsoft Corp (NASDAQ:MSFT), it said in a securities filing on Friday.\n",
    "\n",
    "It received requests for information from the U.S. Securities and Exchange Commission and received a subpoena from a Department of Justice grand jury, the maker of \"Call of Duty\" said in an amended proxy filing.\n",
    "\n",
    "The requests \"appear to relate to their respective investigations into trading by third parties – including persons known to Activision Blizzard's CEO – in securities prior to the announcement of the proposed transaction,\" it said.\n",
    "\n",
    "Microsoft in January agreed to acquire Activision for $95 a share, or $68.7 billion in total, in the biggest video-gaming industry deal in history.\n",
    "\n",
    "The company did not name the parties, nor say whether the grand jury subpoena was directed at any employee.\n",
    "\n",
    "The filing did not disclose when it received the subpoena or the SEC request for information.\n",
    "\n",
    "Media moguls Barry Diller and David Geffen, and investor Alexander von Furstenberg, acquired share options after von Furstenberg met with Activision CEO Bobby Kotick and days before it disclosed the sale to Microsoft, the Wall Street Journal reported last month.\n",
    "\n",
    "\"Activision Blizzard has informed these authorities that it intends to be fully cooperative with these investigations,\" the company said.\n",
    "\n",
    "Diller told Reuters last month that none of the three had any knowledge about a potential acquisition and had acted on the belief that Activision was undervalued and had the potential for going private or being acquired.\n",
    "\n",
    "The amended proxy filing that included the information on its cooperation with the SEC and DOJ came after shareholders sued the company alleging omissions to a preliminary proxy on the sale.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e452a28d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T14:17:58.893468Z",
     "start_time": "2022-04-16T14:17:58.870566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram 개수 : 431\n",
      "trigram 다섯개만 출력 : ['68' '68 billion' '68 billion total' '95' '95 share' '95 share 68'\n",
      " 'acquire' 'acquire activision' 'acquire activision 95' 'acquired']\n"
     ]
    }
   ],
   "source": [
    "# 3개의 단어 묶음인 단어구 추출\n",
    "\n",
    "n_gram_range = (1, 3)\n",
    "stop_words = \"english\"\n",
    "\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc]) #ngram_rangetuple (min_n, max_n), default=(1, 1)\n",
    "candidates = count.get_feature_names_out()\n",
    "\n",
    "print('trigram 개수 :', len(candidates))\n",
    "print('trigram 다섯개만 출력 :', candidates[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0188ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T05:46:01.903767Z",
     "start_time": "2022-04-16T05:45:49.174814Z"
    }
   },
   "outputs": [],
   "source": [
    "# pre-trained model 사용\n",
    "# https://www.sbert.net/docs/pretrained_models.html\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([doc])\n",
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c32ac0b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T05:46:05.475216Z",
     "start_time": "2022-04-16T05:46:05.456294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['known activision blizzard ceo securities', 'von furstenberg met activision ceo', 'activision blizzard ceo securities', 'activision blizzard ceo securities prior', 'blizzard ceo securities prior announcement']\n"
     ]
    }
   ],
   "source": [
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605e3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c478086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b851f1b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:33:50.784392Z",
     "start_time": "2022-04-25T12:33:37.197745Z"
    }
   },
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "doc = \"\"\"\n",
    "         Supervised learning is the machine learning task of learning a function that\n",
    "         maps an input to an output based on example input-output pairs. It infers a\n",
    "         function from labeled training data consisting of a set of training examples.\n",
    "         In supervised learning, each example is a pair consisting of an input object\n",
    "         (typically a vector) and a desired output value (also called the supervisory signal).\n",
    "         A supervised learning algorithm analyzes the training data and produces an inferred function,\n",
    "         which can be used for mapping new examples. An optimal scenario will allow for the\n",
    "         algorithm to correctly determine the class labels for unseen instances. This requires\n",
    "         the learning algorithm to generalize from the training data to unseen situations in a\n",
    "         'reasonable' way (see inductive bias).\n",
    "      \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8234b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:38:14.460981Z",
     "start_time": "2022-04-25T12:38:01.314711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supervised', 0.6676),\n",
       " ('labeled', 0.4896),\n",
       " ('learning', 0.4813),\n",
       " ('training', 0.4134),\n",
       " ('labels', 0.3947)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model = KeyBERT()\n",
    "kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c968b123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:49:40.668856Z",
     "start_time": "2022-04-25T12:49:40.317799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inductive', 0.2577),\n",
       " ('bias', 0.2644),\n",
       " ('function', 0.2658),\n",
       " ('supervisory', 0.3297),\n",
       " ('labels', 0.3947)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(doc,use_maxsum=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6582c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:38:15.081328Z",
     "start_time": "2022-04-25T12:38:14.942698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supervised', 0.6676),\n",
       " ('training', 0.4134),\n",
       " ('function', 0.2658),\n",
       " ('bias', 0.2644),\n",
       " ('inductive', 0.2577)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(doc,use_mmr=True,diversity=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8923d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7b7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5288984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "# [('learning', 0.4604),\n",
    "#  ('algorithm', 0.4556),\n",
    "#  ('training', 0.4487),\n",
    "#  ('class', 0.4086),\n",
    "#  ('mapping', 0.3700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = kw_model.extract_keywords(doc, highlight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2867073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e0885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1cc53b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T05:47:34.786337Z",
     "start_time": "2022-04-16T05:47:34.768385Z"
    }
   },
   "source": [
    "### 다양한 키워드를 얻으려면?\n",
    "* Max Sum Similarity: 후보 간의 유사성을 최소화하면서 문서와의 후보 유사성을 극대화하고자 하는 것\n",
    "* Maximal Marginal Relevance :텍스트 요약 작업에서 중복을 최소화하고 결과의 다양성을 극대화하기 위해 노력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b94da",
   "metadata": {},
   "source": [
    "#### Max Sum Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c596f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def max_sum_sim(doc_embedding, candidate_embeddings, words, top_n, nr_candidates):\n",
    "    # 문서와 각 키워드들 간의 유사도\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    \n",
    "    # 각 키워드들 간의 유사도\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, candidate_embeddings)\n",
    "    \n",
    "    # 코사인 유사도에 기반하여 키워드들 중 상위 top_n개의 단어를 pick\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349021c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce411a2f",
   "metadata": {},
   "source": [
    "#### Maximal Marginal Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmr(doc_embedding, candidate_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # 문서와 각 키워드들 간의 유사도가 적혀있는 리스트\n",
    "    word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    word_similarity = cosine_similarity(candidate_embeddings)\n",
    "\n",
    "    # 문서와 가장 높은 유사도를 가진 키워드의 인덱스를 추출.\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # keywords_idx = [2]\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "\n",
    "    # 가장 높은 유사도를 가진 키워드의 인덱스를 제외한 문서의 인덱스들\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # ==> candidates_idx = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10 ... 중략 ...]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    # 최고의 키워드는 이미 추출했으므로 top_n-1번만큼 아래를 반복.\n",
    "    # ex) top_n = 5라면, 아래의 loop는 4번 반복됨.\n",
    "    for _ in range(top_n - 1):\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # MMR을 계산\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # keywords & candidates를 업데이트\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c520d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56050d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 낮은 diversity\n",
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ad487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b95742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 높은 diversity\n",
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64987a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e1678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "254e03c8",
   "metadata": {},
   "source": [
    "## FinBERT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4edb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecfe20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3fd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2670b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fb5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a48fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
