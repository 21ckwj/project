{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac8871d5",
   "metadata": {},
   "source": [
    "# 챗봇 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72688bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T05:33:04.738576Z",
     "start_time": "2022-06-21T05:33:01.542873Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# telegram\n",
    "import telegram as tel\n",
    "from telegram.ext import Updater\n",
    "from telegram.ext import MessageHandler, Filters\n",
    "from telegram import chat\n",
    "\n",
    "# 크롤링\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "\n",
    "# gpt함수\n",
    "import torch\n",
    "import urllib.request\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8332b29",
   "metadata": {},
   "source": [
    "# 필요 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843d428c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T05:10:34.126912Z",
     "start_time": "2022-06-21T05:10:34.108764Z"
    }
   },
   "outputs": [],
   "source": [
    "kospi_list = pd.read_csv('./data/recent_kospi_list.csv')\n",
    "corp_list = kospi_list['Name']\n",
    "content_lst = ['최신뉴스','최근뉴스']\n",
    "reco_lst1 = ['살만한 주식 뭐 있어?','살만한 종목 뭐 있어?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f56498",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc523d03",
   "metadata": {},
   "source": [
    "## 크롤링 함수: crawl_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac5373a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T05:57:52.155233Z",
     "start_time": "2022-06-21T05:57:52.142268Z"
    }
   },
   "outputs": [],
   "source": [
    "def crawl_news(corp,page=1,num=5,bgn_date='2022.03.01',end_date='2022.03.30'):\n",
    "    \n",
    "    bgn_date1 = bgn_date\n",
    "    bgn_date2 = bgn_date.replace('.','')\n",
    "    end_date1 = end_date\n",
    "    end_date2 = end_date.replace('.','')\n",
    "    \n",
    "    title_lst = []\n",
    "    url_lst = []\n",
    "    date_lst = []\n",
    "\n",
    "    for pg in range(1,page+1):\n",
    "\n",
    "        page_num = pg *10 - 9\n",
    "\n",
    "        url = f'https://search.naver.com/search.naver?where=news&sm=tab_pge&query={corp}&sort=0&photo=0&field=0&pd=3&ds={bgn_date1}&de={end_date1}&cluster_rank=24&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from{bgn_date2}to{end_date2},a:all&start={page_num}'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text , 'html.parser')\n",
    "        lis = soup.select('#main_pack > section > div > div.group_news > ul>li')\n",
    "\n",
    "        for li in lis:\n",
    "            #제목\n",
    "            title = li.select('div.news_wrap.api_ani_send > div > a')[0].text\n",
    "\n",
    "            title_lst.append(title)\n",
    "\n",
    "            # url\n",
    "            url_path = li.select('div.news_wrap.api_ani_send > div > a')[0]['href']\n",
    "            url_lst.append(url_path)\n",
    "\n",
    "            #날짜\n",
    "\n",
    "            if len(li.select('div.news_info > div.info_group > span'))==1:\n",
    "                date = li.select('div.news_info > div.info_group > span')[0].text\n",
    "                date_lst.append(date)\n",
    "\n",
    "\n",
    "            if len(li.select('div.news_info > div.info_group > span'))==2:\n",
    "                date = li.select('div.news_info > div.info_group > span')[1].text\n",
    "                date_lst.append(date)\n",
    "    \n",
    "    df = pd.DataFrame({'날짜':date_lst,'뉴스제목':title_lst,'url':url_lst})\n",
    "    \n",
    "    output_result = ''\n",
    "    for i in range(len(df)):\n",
    "        title = df['뉴스제목'].iloc[i]\n",
    "        news_url = df['url'].iloc[i]\n",
    "        output_result += title + \"\\n\" + news_url + \"\\n\\n\"\n",
    "        if i == num:\n",
    "            break\n",
    "        \n",
    "    return output_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a825099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T05:57:52.748833Z",
     "start_time": "2022-06-21T05:57:52.454218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SSD 1위 삼성전자, 2위 WD와 MOU 체결…\"기술 평준화 위한 협력\"\\nhttp://www.newsis.com/view/?id=NISX20220330_0001813003&cID=13001&pID=13000\\n\\n알아서 척척 \\'캄테크\\' 강조한 한종희…삼성 TV 신제품 공개\\nhttps://www.hankyung.com/economy/article/202203301924g\\n\\n현대重·삼성전자 헬스케어 \\'맞손\\'..입는 의료기기 협력한다\\nhttp://news.mt.co.kr/mtview.php?no=2022033010060122966\\n\\n신보, 삼성전자 냉장가전 협력사에 181억원 보증지원\\nhttp://yna.kr/AKR20220330048700002?did=1195m\\n\\n삼성전자, 태국에 초대형 마이크로 LED ‘더 월’ 설치\\nhttps://biz.chosun.com/it-science/ict/2022/03/29/ZL3KVAX2OZBMBPWBGKX5GL4XYE/?utm_source=naver&utm_medium=original&utm_campaign=biz\\n\\n[단독]검찰, 삼성웰스토리·삼성전자 본사 3일째 연달아 압수수색\\nhttps://www.seoul.co.kr/news/newsView.php?id=20220330500036&wlog_tag3=naver\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawl_news('삼성전자')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f05e3b",
   "metadata": {},
   "source": [
    "## gpt함수: finance_gpt(user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6c39190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T05:47:03.918538Z",
     "start_time": "2022-06-21T05:46:58.806134Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "Q_TKN = \"<usr>\"\n",
    "A_TKN = \"<sys>\"\n",
    "BOS = '</s>'\n",
    "EOS = '</s>'\n",
    "MASK = '<unused0>'\n",
    "SENT = '<unused1>'\n",
    "PAD = '<pad>'\n",
    "\n",
    "model1 = torch.load('./data/GPT2_model/gpt_finance.pth')\n",
    "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n",
    "            pad_token=PAD, mask_token=MASK) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ba1ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T05:47:06.049091Z",
     "start_time": "2022-06-21T05:47:06.038120Z"
    }
   },
   "outputs": [],
   "source": [
    "def finance_gpt(user_text):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        answer = \"\"\n",
    "        while 1:\n",
    "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + user_text + SENT + A_TKN + answer)).unsqueeze(dim=0)\n",
    "            pred = model1(input_ids)\n",
    "            pred = pred.logits\n",
    "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n",
    "            if gen == EOS:\n",
    "                break\n",
    "            answer += gen.replace(\"▁\", \" \").strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df532e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T05:47:09.249316Z",
     "start_time": "2022-06-21T05:47:08.950116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'능력이있으면하면되죠'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_gpt('주식 해도 될까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b2e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5075f899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T03:17:23.401254Z",
     "start_time": "2022-06-21T03:16:29.384374Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user > 주식 투자할까?\n",
      "Chatbot > 어떻게 하느냐에 따라 다를 것 같아요\n",
      "user > 시가총액이뭐야\n",
      "Chatbot > 금융시장에서 유통되는 주식이 현재거래가격기준으로 총 얼마의 가치를 가지는지 나타내는 지표입니다\n",
      "user > quit\n"
     ]
    }
   ],
   "source": [
    "model1 = torch.load('./data/GPT2_model/gpt_finance.pth')\n",
    "Q_TKN = \"<usr>\"\n",
    "A_TKN = \"<sys>\"\n",
    "BOS = '</s>'\n",
    "EOS = '</s>'\n",
    "MASK = '<unused0>'\n",
    "SENT = '<unused1>'\n",
    "PAD = '<pad>'\n",
    "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n",
    "            pad_token=PAD, mask_token=MASK) \n",
    "\n",
    "with torch.no_grad():\n",
    "    while 1:\n",
    "        q = input(\"user > \").strip()\n",
    "        if q == \"quit\":\n",
    "            break\n",
    "        a = \"\"\n",
    "        while 1:\n",
    "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + A_TKN + a)).unsqueeze(dim=0)\n",
    "            pred = model1(input_ids)\n",
    "            pred = pred.logits\n",
    "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n",
    "            if gen == EOS:\n",
    "                break\n",
    "            a += gen.replace(\"▁\", \" \")\n",
    "        print(\"Chatbot > {}\".format(a.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec02be2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T03:37:22.258332Z",
     "start_time": "2022-06-21T03:37:21.071854Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1820867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "937e5452",
   "metadata": {},
   "source": [
    "# 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a06cbf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T06:31:04.514773Z",
     "start_time": "2022-06-21T06:30:56.118942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# telegram\n",
    "import telegram\n",
    "from telegram.ext import Updater\n",
    "from telegram.ext import MessageHandler, Filters\n",
    "from telegram import chat\n",
    "\n",
    "# 크롤링\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "\n",
    "# gpt함수\n",
    "import torch\n",
    "import urllib.request\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "Q_TKN = \"<usr>\"\n",
    "A_TKN = \"<sys>\"\n",
    "BOS = '</s>'\n",
    "EOS = '</s>'\n",
    "MASK = '<unused0>'\n",
    "SENT = '<unused1>'\n",
    "PAD = '<pad>'\n",
    "\n",
    "model1 = torch.load('./data/GPT2_model/gpt_finance.pth')\n",
    "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n",
    "            pad_token=PAD, mask_token=MASK) \n",
    "\n",
    "kospi_list = pd.read_csv('./data/recent_kospi_list.csv')\n",
    "corp_list = kospi_list['Name']\n",
    "content_lst = ['최신뉴스','최근뉴스']\n",
    "\n",
    "reco_lst1 = ['살만한 주식 뭐 있어?','살만한 종목 뭐 있어?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8908bc6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T06:31:48.422998Z",
     "start_time": "2022-06-21T06:31:46.183181Z"
    },
    "code_folding": [
     2,
     55
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<queue.Queue at 0x1fb74fc1b20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ######## 크롤링 관련 함수 ########\n",
    "\n",
    "def crawl_news(corp,page=1,num=5,bgn_date='2022.03.01',end_date='2022.03.30'):\n",
    "    \n",
    "    bgn_date1 = bgn_date\n",
    "    bgn_date2 = bgn_date.replace('.','')\n",
    "    end_date1 = end_date\n",
    "    end_date2 = end_date.replace('.','')\n",
    "    \n",
    "    title_lst = []\n",
    "    url_lst = []\n",
    "    date_lst = []\n",
    "\n",
    "    for pg in range(1,page+1):\n",
    "\n",
    "        page_num = pg *10 - 9\n",
    "\n",
    "        url = f'https://search.naver.com/search.naver?where=news&sm=tab_pge&query={corp}&sort=0&photo=0&field=0&pd=3&ds={bgn_date1}&de={end_date1}&cluster_rank=24&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from{bgn_date2}to{end_date2},a:all&start={page_num}'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text , 'html.parser')\n",
    "        lis = soup.select('#main_pack > section > div > div.group_news > ul>li')\n",
    "\n",
    "        for li in lis:\n",
    "            #제목\n",
    "            title = li.select('div.news_wrap.api_ani_send > div > a')[0].text\n",
    "\n",
    "            title_lst.append(title)\n",
    "\n",
    "            # url\n",
    "            url_path = li.select('div.news_wrap.api_ani_send > div > a')[0]['href']\n",
    "            url_lst.append(url_path)\n",
    "\n",
    "            #날짜\n",
    "\n",
    "            if len(li.select('div.news_info > div.info_group > span'))==1:\n",
    "                date = li.select('div.news_info > div.info_group > span')[0].text\n",
    "                date_lst.append(date)\n",
    "\n",
    "\n",
    "            if len(li.select('div.news_info > div.info_group > span'))==2:\n",
    "                date = li.select('div.news_info > div.info_group > span')[1].text\n",
    "                date_lst.append(date)\n",
    "    \n",
    "    df = pd.DataFrame({'날짜':date_lst,'뉴스제목':title_lst,'url':url_lst})\n",
    "    \n",
    "    output_result = ''\n",
    "    for i in range(len(df)):\n",
    "        title = df['뉴스제목'].iloc[i]\n",
    "        news_url = df['url'].iloc[i]\n",
    "        output_result += title + \"\\n\" + news_url + \"\\n\\n\"\n",
    "        if i == num:\n",
    "            break\n",
    "        \n",
    "    return output_result\n",
    "\n",
    "def finance_gpt(user_text):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        answer = \"\"\n",
    "        while 1:\n",
    "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + user_text + SENT + A_TKN + answer)).unsqueeze(dim=0)\n",
    "            pred = model1(input_ids)\n",
    "            pred = pred.logits\n",
    "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n",
    "            if gen == EOS:\n",
    "                break\n",
    "            answer += gen.replace(\"▁\", \" \").strip()\n",
    "    return answer\n",
    "####################################\n",
    " \n",
    "######## 텔레그램 관련 코드 ########\n",
    "token = \"5403110188:AAEbcgi6cDNmgdRHERhGhprFQgMUHzi-rtI\"\n",
    "id = 5322933876\n",
    " \n",
    "bot = telegram.Bot(token)\n",
    "info_message = '''안녕하세요 금융챗봇 고슴도치입니다'''\n",
    "bot.sendMessage(chat_id=id, text=info_message)\n",
    " \n",
    "updater = Updater(token=token, use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "updater.start_polling()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c64d4b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T06:31:55.748933Z",
     "start_time": "2022-06-21T06:31:55.734942Z"
    },
    "code_folding": [
     2,
     55
    ]
   },
   "outputs": [],
   "source": [
    "### 챗봇 답장\n",
    "\n",
    "def handler(update, context): \n",
    "    user_text = update.message.text # 사용자가 보낸 메세지 user_text 변수에 저장\n",
    "    user_words = user_text.split()\n",
    "    \n",
    "    # 종목명 찾기\n",
    "    for word in user_words:\n",
    "        # 종목명을 포함한다면\n",
    "        if word in corp_list.tolist():\n",
    "            corp = [w for w in user_words if w in corp_list.tolist()][0]\n",
    "            break\n",
    "        else:\n",
    "            corp='종목명 없음'\n",
    "\n",
    "    # 종목명 없으면 gpt or 추천\n",
    "    if corp == '종목명 없음':\n",
    "        # 살만한 주식 뭐있어?\n",
    "        if user_text in reco_lst1:\n",
    "            bot.send_message(chat_id=id, text='고슴도치가 추천해드리겠습니다') # 답장 보내기\n",
    "            \n",
    "        # gpt일반대화\n",
    "        else:\n",
    "            answer = finance_gpt(user_text)\n",
    "            bot.send_message(chat_id=id, text=answer) # 답장 보내기\n",
    "    \n",
    "    # 종목명 있으면\n",
    "    else:\n",
    "        for word in user_words:\n",
    "            # 최신뉴스 최근뉴스 포함시\n",
    "            if word in content_lst:\n",
    "                crawl_news = crawl_news(corp)\n",
    "                bot.send_message(chat_id=id, text=crawl_news)\n",
    "                break\n",
    "\n",
    "echo_handler = MessageHandler(Filters.text, handler)\n",
    "dispatcher.add_handler(echo_handler)\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacde4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ecec9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T06:27:09.272207Z",
     "start_time": "2022-06-21T06:27:09.255253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['최신뉴스', '알려줘']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_text = '최신뉴스 알려줘'\n",
    "user_words = user_text.split()\n",
    "user_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "511f5ed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T06:27:09.786831Z",
     "start_time": "2022-06-21T06:27:09.782843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'종목명 없음'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b5fa743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T06:29:18.809885Z",
     "start_time": "2022-06-21T06:29:18.790936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'종목명 없음'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 종목명 찾기\n",
    "for word in user_words:\n",
    "    # 종목명을 포함한다면\n",
    "    if word in corp_list.tolist():\n",
    "        corp = [w for w in user_words if w in corp_list.tolist()][0]\n",
    "        break\n",
    "    else:\n",
    "        corp='종목명 없음'\n",
    "        break\n",
    "corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0aadda66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T06:29:37.310424Z",
     "start_time": "2022-06-21T06:29:22.809193Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while getting Updates: Conflict: terminated by other getUpdates request; make sure that only one bot instance is running\n",
      "Error while getting Updates: Conflict: terminated by other getUpdates request; make sure that only one bot instance is running\n",
      "Error while getting Updates: Conflict: terminated by other getUpdates request; make sure that only one bot instance is running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_700/147066610.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# gpt일반대화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinance_gpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchat_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 답장 보내기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_700/1317571829.py\u001b[0m in \u001b[0;36mfinance_gpt\u001b[1;34m(user_text)\u001b[0m\n\u001b[0;32m     60\u001b[0m        \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m            \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkoGPT2_TOKENIZER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_TKN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0muser_text\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mSENT\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mA_TKN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m            \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m            \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m            \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkoGPT2_TOKENIZER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[0;32m   1048\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    888\u001b[0m                 )\n\u001b[0;32m    889\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m                 outputs = block(\n\u001b[0m\u001b[0;32m    891\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         attn_outputs = self.attn(\n\u001b[0m\u001b[0;32m    396\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   2325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2326\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2327\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2328\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 종목명 없으면 gpt or 추천\n",
    "if corp == '종목명 없음':\n",
    "    # 살만한 주식 뭐있어?\n",
    "    if user_text in reco_lst1:\n",
    "        bot.send_message(chat_id=id, text='고슴도치가 추천해드리겠습니다') # 답장 보내기\n",
    "\n",
    "    # gpt일반대화\n",
    "    else:\n",
    "        answer = finance_gpt(user_text)\n",
    "        bot.send_message(chat_id=id, text=answer) # 답장 보내기\n",
    "\n",
    "# 종목명 있으면\n",
    "else:\n",
    "    for word in user_words:\n",
    "        # 최신뉴스 최근뉴스 포함시\n",
    "        if word in content_lst:\n",
    "            crawl_news = crawl_news(corp)\n",
    "            bot.send_message(chat_id=id, text=crawl_news)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "429c8f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T06:04:49.582047Z",
     "start_time": "2022-06-21T06:03:36.299968Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_700/1726163250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinance_gpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_700/4132698691.py\u001b[0m in \u001b[0;36mfinance_gpt\u001b[1;34m(user_text)\u001b[0m\n\u001b[0;32m     60\u001b[0m        \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m            \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkoGPT2_TOKENIZER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_TKN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0muser_text\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mSENT\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mA_TKN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m            \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m            \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m            \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkoGPT2_TOKENIZER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[0;32m   1048\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    888\u001b[0m                 )\n\u001b[0;32m    889\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m                 outputs = block(\n\u001b[0m\u001b[0;32m    891\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m         \u001b[1;31m# residual connection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   2325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2326\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2327\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2328\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "finance_gpt(user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b29306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55f846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf6023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21386305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T05:14:34.333194Z",
     "start_time": "2022-06-21T05:14:32.085668Z"
    },
    "code_folding": [
     27,
     80
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# telegram\n",
    "import telegram as tel\n",
    "from telegram.ext import Updater\n",
    "from telegram.ext import MessageHandler, Filters\n",
    "from telegram import chat\n",
    "\n",
    "# 크롤링\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "\n",
    "# gpt함수\n",
    "import torch\n",
    "import urllib.request\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import GPT2LMHeadModel\n",
    " \n",
    "######## 크롤링 관련 함수 ########\n",
    "\n",
    "def crawl_news(corp,page=1,num=5,bgn_date='2022.03.01',end_date='2022.03.30'):\n",
    "    \n",
    "    bgn_date1 = bgn_date\n",
    "    bgn_date2 = bgn_date.replace('.','')\n",
    "    end_date1 = end_date\n",
    "    end_date2 = end_date.replace('.','')\n",
    "    \n",
    "    title_lst = []\n",
    "    url_lst = []\n",
    "    date_lst = []\n",
    "\n",
    "    for pg in range(1,page+1):\n",
    "\n",
    "        page_num = pg *10 - 9\n",
    "\n",
    "        url = f'https://search.naver.com/search.naver?where=news&sm=tab_pge&query={corp}&sort=0&photo=0&field=0&pd=3&ds={bgn_date1}&de={end_date1}&cluster_rank=24&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from{bgn_date2}to{end_date2},a:all&start={page_num}'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text , 'html.parser')\n",
    "        lis = soup.select('#main_pack > section > div > div.group_news > ul>li')\n",
    "\n",
    "        for li in lis:\n",
    "            #제목\n",
    "            title = li.select('div.news_wrap.api_ani_send > div > a')[0].text\n",
    "\n",
    "            title_lst.append(title)\n",
    "\n",
    "            # url\n",
    "            url_path = li.select('div.news_wrap.api_ani_send > div > a')[0]['href']\n",
    "            url_lst.append(url_path)\n",
    "\n",
    "            #날짜\n",
    "\n",
    "            if len(li.select('div.news_info > div.info_group > span'))==1:\n",
    "                date = li.select('div.news_info > div.info_group > span')[0].text\n",
    "                date_lst.append(date)\n",
    "\n",
    "\n",
    "            if len(li.select('div.news_info > div.info_group > span'))==2:\n",
    "                date = li.select('div.news_info > div.info_group > span')[1].text\n",
    "                date_lst.append(date)\n",
    "    \n",
    "    df = pd.DataFrame({'날짜':date_lst,'뉴스제목':title_lst,'url':url_lst})\n",
    "    \n",
    "    output_result = ''\n",
    "    for i in range(len(df)):\n",
    "        title = df['뉴스제목'].iloc[i]\n",
    "        news_url = df['url'].iloc[i]\n",
    "        output_result += title + \"\\n\" + news_url + \"\\n\\n\"\n",
    "        if i == num:\n",
    "            break\n",
    "        \n",
    "    return output_result\n",
    "\n",
    "def finance_gpt(user_text):\n",
    "    user_text = update.message.text\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        answer = \"\"\n",
    "        while 1:\n",
    "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + user_text + SENT + A_TKN + answer)).unsqueeze(dim=0)\n",
    "            pred = model1(input_ids)\n",
    "            pred = pred.logits\n",
    "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n",
    "            if gen == EOS:\n",
    "                break\n",
    "            answer += gen.replace(\"▁\", \" \").strip()\n",
    "    return answer\n",
    "####################################\n",
    " \n",
    "######## 텔레그램 관련 코드 ########\n",
    "token = \"5403110188:AAEbcgi6cDNmgdRHERhGhprFQgMUHzi-rtI\"\n",
    "id = 5322933876\n",
    " \n",
    "bot = telegram.Bot(token)\n",
    "info_message = '''안녕하세요 금융챗봇 고슴도치입니다'''\n",
    "bot.sendMessage(chat_id=id, text=info_message)\n",
    " \n",
    "updater = Updater(token=token, use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "updater.start_polling()\n",
    " \n",
    "### 챗봇 답장\n",
    "\n",
    "def handler(update, context): \n",
    "    user_text = update.message.text # 사용자가 보낸 메세지 user_text 변수에 저장\n",
    "    user_words = user_text.split()\n",
    "    \n",
    "    for word in user_words:\n",
    "        # 종목명을 포함한다면\n",
    "        if word in corp_list.tolist():\n",
    "            corp = [w for w in user_words if w in corp_list.tolist()]\n",
    "            user_words1 = user_words.remove(corp)\n",
    "            \n",
    "            # 최신뉴스, 최근뉴스 포함한다면\n",
    "            for word1 in user_words1:\n",
    "                if word1 in content_lst:\n",
    "                    crawl_news = crawl_news(corp)\n",
    "                    bot.send_message(chat_id=id, text=crawl_news)\n",
    "                    break\n",
    "          \n",
    "        \n",
    "        # 종목명을 포함하지 않는경우\n",
    "        else:\n",
    "            #1: 주식 추천해줘\n",
    "            if user_text in reco_lst1:\n",
    "                bot.send_message(chat_id=id, text='고슴도치가 추천해드리겠습니다') # 답장 보내기\n",
    "                break\n",
    "#             elif\n",
    "\n",
    "            else:    \n",
    "                answer = finance_gpt(user_text)\n",
    "                bot.send_message(chat_id=id, text=answer) # 답장 보내기\n",
    "                break\n",
    "            \n",
    " \n",
    "echo_handler = MessageHandler(Filters.text, handler)\n",
    "dispatcher.add_handler(echo_handler)\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c0bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133d097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec6ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
